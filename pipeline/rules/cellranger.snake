# ===== Snakemake rules for running the 10x Cell Ranger pipeline ===============


# Merge fastqs and create symlinks =============================================
# This rule will either merge multiple fastqs into a single file or create a 
# symlink to the original fastq. If a comma separated list of sample names is 
# provided all fastqs that begin with either name will be merged into one file 
# that has a new name. If only a single name is provided a symlink will be 
# created for each fastq that begins with the name.
#
# This rule was written to handle ADT and HTO data. When ADT and HTO files
# are specified together in the sample csv an error is thrown.

rule merge_fastqs:
    output:
        touch(RESULTS + "/logs/.merge_fastqs_done")
    params:
        job_name = "merge_fastqs",
        memory   = "select[mem>4] rusage[mem=4]",
        raw_data = RAW_DATA,
        fq_dir   = FASTQ_DIR,
        fq_regex = FASTQ_REGEX,
        rna      = RNA_SAMPLES,
        adt      = ADT_SAMPLES,
        vdj      = VDJ_SAMPLES
    log:
        out = RESULTS + "/logs/merge_fastqs.out",
        err = RESULTS + "/logs/merge_fastqs.err"
    threads:
        1
    run:
        # Function to retrieve fastq paths
        def _get_fq_paths(sample, read):
            path_list = []

            for dir in params.raw_data:
                fq_paths = os.path.join(dir, sample + "*" + read + "*.fastq.gz") 
                fq_paths = glob.glob(os.path.abspath(fq_paths))
                fq_paths = sorted(fq_paths)

                if fq_paths:
                    [path_list.append(x) for x in fq_paths]

            if not path_list:
                sys.exit("ERROR: No fastqs found for " + sample + ".") 
                          
            return sorted(path_list)

        # Function to build merge command
        def _build_merge_cmd(path_list, merged_path):
            cmds = ""

            for fq_path in path_list:
                cmds += " " + fq_path

            cmds = "cat" + cmds + " > " + merged_path

            return cmds

        # Function to merge fastq files or create symlink
        def _merge_fastqs(sample, merged_name):

            # Merge fastqs for each read or create a symlink
            for read in ["_R1_", "_R2_"]:
                names = sample.split(",")

                # Create list of commands for creating symlinks
                if len(names) == 1:
                    path_list = _get_fq_paths(names[0], read)

                    cmd_list = ["ln -s " + x + " " + params.fq_dir + "/" + os.path.basename(x) for x in path_list]

                # Create list of commands for merging fastqs
                else:
                    path_list = []

                    for name in names:
                        [path_list.append(x) for x in _get_fq_paths(name, read)]

                    fq_info     = re.search(params.fq_regex, path_list[0]).group(0)
                    merged_path = os.path.join(params.fq_dir, merged_name + fq_info)
                    cmd_list    = [_build_merge_cmd(path_list, merged_path)]  

                for cmd in cmd_list:
                    subprocess.run(cmd, shell = True)

        # Create symlinks for gene expression fastqs
        if params.rna:
            [_merge_fastqs(x, x) for x in params.rna]

        # Merge CITE-seq and cell hashing fastqs
        if params.adt:
            merged_names = [re.sub(",", "_", x) for x in params.adt]

            [_merge_fastqs(x, y) for x, y in zip(params.adt, merged_names)]

        # Create symlinks for VDJ fastqs
        if params.vdj:
            [_merge_fastqs(x, x) for x in params.vdj]



# Create antibody csv ==========================================================
# This rule creates a csv file used by cellranger count that contains the 
# antibody names, barcode sequences, and barcode position.

rule create_ab_csv:
    input:
        RESULTS + "/logs/.merge_fastqs_done"
    output:
        touch(RESULTS + "/logs/.antibody_csv_done")
    params:
        job_name = "antibody_csv",
        memory   = "select[mem>4] rusage[mem=4]",
        results  = RESULTS,
        adt      = ADT_SAMPLES,
        adt_ref  = ADT_REF,
        abs      = ANTIBODIES
    log:
        out = RESULTS + "/logs/antibody_csv.out",
        err = RESULTS + "/logs/antibody_csv.err"
    threads:
        1
    run:
        if params.adt:
            ab_csv = params.results + "/antibodies.csv"

            if params.abs:
                with open(ab_csv, "w") as ab_csv:
                    ab_csv.write("id,name,read,pattern,sequence,feature_type\n")
                
                    # Iterate through antibody list
                    # The antibody ID should be the first column
                    for ab in params.abs:
                        ab_regex = "^" + ab + ",.+"
                        match    = False

                        # Search for antibody in reference
                        for line in open(params.adt_ref):
                            ab_match = re.search(ab_regex, line)

                            if ab_match:
                                ab_csv.write(ab_match.group(0) + "\n")

                                if match:
                                    sys.exit("ERROR: " + ab + " matches multiple entries in the reference file.")

                                match = True

                        if not match:
                            sys.exit("ERROR: " + ab + " was not found in the reference file.")

            else:
                shutil.copyfile(params.adt_ref, ab_csv)



# Create sample csv ============================================================
# This rule creates a csv file used by cellranger count that contains the path 
# to the fastq directory, each fastq prefix, and the library type.

rule create_sample_csv:
    input:
        RESULTS + "/logs/.antibody_csv_done"
    output:
        touch(RESULTS + "/logs/.{sample}_csv_done")
    params:
        job_name = "sample_csv",
        memory   = "select[mem>4] rusage[mem=4]",
        results  = RESULTS,
        fq_dir   = FASTQ_DIR,
        fq_regex = FASTQ_REGEX,
        rna      = RNA_SAMPLES,
        adt      = ADT_SAMPLES
    log:
        out = RESULTS + "/logs/{sample}_csv.out",
        err = RESULTS + "/logs/{sample}_csv.err"
    threads:
        1
    run:
        # Function to create sample csv file for cellranger count
        def _create_sample_csv(sample_name, lib_type, sample_csv):
            fq_path = os.path.join(params.fq_dir, sample_name + "*.fastq.gz")
            fastqs  = glob.glob(fq_path)
            R1_fqs  = [x for x in fastqs if "_R1_" in x]

            # Trim fastq names
            R1_fqs = [os.path.basename(x) for x in R1_fqs]
            R1_fqs = [re.sub(params.fq_regex, "", x) for x in R1_fqs]
            R1_fqs = set(R1_fqs)

            # Create sample csv
            if not os.path.isfile(sample_csv):
                with open(sample_csv, "w") as csv:
                    csv.write("fastqs,sample,library_type\n")

            with open(sample_csv, "a") as csv:
                for fq in R1_fqs:
                    csv.write("%s,%s,%s\n" % (params.fq_dir, fq, lib_type))

        # Create sample csv file for cellranger count
        sample_csv = os.path.join(params.results, wildcards.sample + ".csv")

        if os.path.isfile(sample_csv):
            os.remove(sample_csv)

        if params.rna and params.adt:
            rna_id, adt_id = wildcards.sample.split("-")
            _create_sample_csv(rna_id, "Gene Expression", sample_csv)
            _create_sample_csv(adt_id, "Antibody Capture", sample_csv)

        elif params.rna:
            _create_sample_csv(wildcards.sample, "Gene Expression", sample_csv)

        elif params.adt:
            _create_sample_csv(wildcards.sample, "Antibody Capture", sample_csv)



# Run cellranger count =========================================================
# This rule runs cellranger count using csv files from create_sample_csv and 
# create_ab_csv.

rule cellranger_count:
    input:
        RESULTS + "/logs/.{sample}_csv_done"
    output:
        touch(RESULTS + "/logs/.{sample}_count_done")
    params:
        job_name = "count",
        memory   = "select[mem>4] rusage[mem=4]",
        results  = RESULTS,
        rna      = RNA_SAMPLES,
        adt      = ADT_SAMPLES,
        genome   = GENOME,
        chem     = CHEM,
        max_jobs = MAX_JOBS,
        lsf      = LSF_TEMPLATE
    log:
        out = RESULTS + "/logs/{sample}_count.out",
        err = RESULTS + "/logs/{sample}_count.err"
    threads:
        1
    run:
        # Run cellranger count for CITE-seq and gene expression
        if params.adt:
            shell(
                """
                sample_csv={wildcards.sample}.csv
                ab_csv=antibodies.csv

                cd {params.results}

                cellranger count \
                    --id={wildcards.sample} \
                    --libraries=$sample_csv \
                    --feature-ref=$ab_csv \
                    --transcriptome={params.genome} \
                    --jobmode={params.lsf} \
                    --maxjobs={params.max_jobs} \
                    --chemistry={params.chem}
                """
            )

        # Run cellranger count just for gene expression
        elif params.rna:
            shell(
                """
                sample_csv={wildcards.sample}.csv

                cd {params.results}

                cellranger count \
                    --id={wildcards.sample} \
                    --libraries=$sample_csv \
                    --transcriptome={params.genome} \
                    --jobmode={params.lsf} \
                    --maxjobs={params.max_jobs} \
                    --chemistry={params.chem}
                """
            )

        # Add sample names for output files
        if params.rna or params.adt:
            sample  = wildcards.sample
            out_dir = os.path.join(params.results, sample, "outs/")

            shutil.copyfile(out_dir + "web_summary.html", out_dir + sample + ".html")
            shutil.copyfile(out_dir + "cloupe.cloupe", out_dir + sample + ".cloupe")



# Create cellranger count summary ==============================================
# This rule combines the metrics_summary.csv files from each run

rule count_metrics:
    input:
        expand(
            RESULTS + "/logs/.{sample}_count_done",
            sample = SAMPLES
        )
    output:
        RESULTS + "/count_metrics.csv"
    params:
        job_name = "count_metrics",
        memory   = "select[mem>4] rusage[mem=4]",
        results  = RESULTS,
        samples  = SAMPLES
    log:
        out = RESULTS + "/logs/count_metrics.out",
        err = RESULTS + "/logs/count_metrics.err"
    threads:
        1
    shell:
        """
        sams=({params.samples})

        header=$(head -1 {params.results}/${{sams[0]}}/outs/metrics_summary.csv)

        echo "$header,sample" \
            > {output}

        for sam in ${{sams[@]}}
        do
            stats=$(tail -1 {params.results}/$sam/outs/metrics_summary.csv)

            echo "$stats,$sam" \
                >> {output}
        done
        """



# Run cellranger aggr ==========================================================
# This rule creates a csv file containing the sample names and the path to each 
# molecule_info.h5 file and runs cellranger aggr.

# rule cellranger_aggr:
#     input:
#         expand(
#             RESULTS + "/logs/.{sample}_count_done",
#             sample = SAMPLES
#         )
#     output:
#         RESULTS + "/logs/.{group}_aggr_done"
#     params:
#         job_name = "aggr",
#         memory   = "select[mem>4] rusage[mem=4]",
#         results  = RESULTS,
#         samples  = SAMPLES,
#         groups   = GROUPS,
#         max_jobs = MAX_JOBS,
#         lsf      = LSF_TEMPLATE
#     log:
#         out = RESULTS + "/logs/{group}_aggr.out",
#         err = RESULTS + "/logs/{group}_aggr.err"
#     threads:
#         1
#     run:
#         # Run cellranger aggr
#         if params.groups:
#             samples       = ",".join(params.samples)
#             group_names   = wildcards.group.split("-")
#             group_samples = [re.findall(x + "[a-zA-Z0-9\-_]+", samples) for x in group_names]
#             
#             # Check that all group samples are in RNA_SAMPLES
#             def _check_value(name, val):
#                 if not val:
#                     sys.exit("ERROR: Unable to find " + name + " in SAMPLES.")
#                 elif len(val) > 1:
#                     sys.exit("ERROR: Multiple matches for " + name + " were found in SAMPLES.")
# 
#             [_check_value(x, y) for x, y in zip(group_names, group_samples)]
#             group_samples = ["".join(x) for x in group_samples]
# 
#             # Check for aggr csv
#             aggr_csv = os.path.join(params.results, wildcards.group + "_aggr.csv")
#     
#             if not os.path.isfile(aggr_csv):
#                 with open(aggr_csv, "w") as csv:
#                     csv.write("library_id,molecule_h5\n")
# 
#             # Append sample info to aggr csv
#             with open(aggr_csv, "a") as csv:
#                 for sample in group_samples:
#                     h5_path = os.path.join(params.results, sample, "outs/molecule_info.h5")
#                     csv.write("%s,%s\n" % (sample, h5_path))
# 
#             # Run cellranger aggr
#             shell(
#                 """
#                 aggr_csv={wildcards.group}_aggr.csv
# 
#                 cd {params.results}
# 
#                 cellranger aggr \
#                     --id={wildcards.group} \
#                     --csv=$aggr_csv \
#                     --jobmode={params.lsf} \
#                     --maxjobs={params.max_jobs} 
#                 """
#             )
# 
#             # Add sample names for output files
#             group   = wildcards.group
#             out_dir = os.path.join(params.results, group, "outs/")
# 
#             shutil.copyfile(out_dir + "web_summary.html", out_dir + group + ".html")
#             shutil.copyfile(out_dir + "cloupe.cloupe", out_dir + group + ".cloupe")
#         
#         # Write output file
#         with open(output[0], "w") as out:
#             out.write("done\n")



# Run cellranger vdj ===========================================================
# This rule generates IDs for VDJ fastqs and runs cellranger vdj.

def _get_fq_ids(wildcards):
    fqs    = glob.glob(os.path.join(FASTQ_DIR, wildcards.vdj_sample + "*"))
    R1_fqs = [x for x in fqs if "R1" in x]
    R1_fqs = [os.path.basename(x) for x in R1_fqs]

    fq_ids = set()

    for fq in R1_fqs:
        fq_id = re.sub(FASTQ_REGEX, "", fq)
        fq_ids.add(fq_id)
    
        if not re.search(FASTQ_REGEX, fq):
            sys.exit("ERROR: Unable to parse sample ID for " + fq + ".")

    return ",".join(fq_ids)


rule cellranger_vdj:
    input:
        RESULTS + "/logs/.merge_fastqs_done"
    output:
        touch(RESULTS + "/logs/.{vdj_sample}_vdj_done")
    params:
        job_name = "vdj",
        memory   = "select[mem>32] rusage[mem=32]",
        fq_ids   = _get_fq_ids,
        results  = RESULTS,
        fq_dir   = FASTQ_DIR,
        vdj      = VDJ_SAMPLES,
        vdj_ref  = VDJ_REF,
        max_jobs = MAX_JOBS,
        lsf      = LSF_TEMPLATE
    log:
        out = RESULTS + "/logs/{vdj_sample}_vdj.out",
        err = RESULTS + "/logs/{vdj_sample}_vdj.err"
    threads:
        1
    run:
        # Run cellranger vdj
        if params.vdj:
            shell(
                """
                cd {params.results}

                cellranger vdj \
                    --id={wildcards.vdj_sample} \
                    --fastqs={params.fq_dir} \
                    --sample={params.fq_ids} \
                    --reference={params.vdj_ref} \
                    --jobmode={params.lsf} \
                    --maxjobs={params.max_jobs}
                """
            )

            # Copy output files to outer directory
            sample = wildcards.vdj_sample
            out_dir = os.path.join(params.results, sample, "outs/")

            shutil.copyfile(out_dir + "web_summary.html", out_dir + sample + ".html")
            shutil.copyfile(out_dir + "vloupe.vloupe", out_dir + sample + ".vloupe")


